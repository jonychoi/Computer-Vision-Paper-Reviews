{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YOLOv4: Optimal Speed and Accuracy of Object Detection**\n",
    "\n",
    "**Authors: Alexey Bochkovskiy {alexeyab84@gmail.com}, Chien-Yao Wang {kinyiu@iis.sinica.edu.tw}, Hong-Yuan Mark Liao {liao@iis.sinica.edu.tw}**\n",
    "\n",
    "**Official Github**: https://github.com/AlexeyAB/darknet\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 7 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **::Abstract::**\n",
    "\n",
    "So far, there are a huge number of **features** to improve the **CNN Accuracy**.\n",
    "\n",
    "- Some features are applicable on certain **exclusive environment(e.g models, problems etc.)**\n",
    "\n",
    "- And some features are applicable to the majority of models, tasks, and datasets. **(e.g small-scale datsets, batch-normalization, residual-connections etc.)**.\n",
    "\n",
    "The authors assumed that there are **universal features**, and created the new features belows\n",
    "\n",
    "- **WRC**: Weighted-Residual-Connections\n",
    "- **CSP**: Cross-Stage-Partial-connections\n",
    "- **CmBN**: Cross mini-Batch Normalization\n",
    "- **SAT**: Self-adversarial-training\n",
    "- **Mish-activation**\n",
    "\n",
    "+ Also they used other new feautures below (not assumed the universal features in context of abstract)\n",
    "\n",
    "- Mosaic data augmentation\n",
    "- DropBlock regularization\n",
    "- CIOU loss\n",
    "\n",
    "With using new **features**, and combining some of them, they achieved\n",
    "\n",
    "- **state-of-the-art results: 43.5% AP (65.7% AP50)** \n",
    "- for the MS COCO dataset\n",
    "- at a **realtime speed of âˆ¼65 FPS**\n",
    "- on Tesla V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **::Introduction::**\n",
    "\n",
    "#### **1. Trade offs between Accuracy & Speed**\n",
    "The majority of CNN-based object detectors are largely applicable **only** for recommendation systems.\n",
    "- **Example of Slow Accurate Models**: Searching Free parking place\n",
    "\n",
    "- **Example of Fast Inaccurate Models**: Car collision warning\n",
    "\n",
    "#### **2. Problems Authors Object**\n",
    "\n",
    "- The most accurate modern neural networks **do not operate in real time**.\n",
    "- The most accurate modern neural networks **require large number of GPUs** for training with a large mini-batch-size.\n",
    "\n",
    "#### **3. Solutions Authors Object**\n",
    "- Creating a CNN that operates **in real-time on a conventional GPU**.\n",
    "- Creating a CNN that **training requires only one conventional GPU** like 1080Ti for everyone can train.\n",
    "\n",
    "#### **4. Main Goal**\n",
    "\n",
    "- **Designing a fast operating speed of an object detector in production systems and optimization for parallel computations that can be easily trained and used.**\n",
    "\n",
    "#### **5. Contributions**\n",
    "\n",
    "1. **Develop an efficient and powerful object detection model that everyone can use a 1080 Ti or 2080 Ti GPU to train.**\n",
    "\n",
    "2. Verify the influence of state-of-the-art Bag-ofFreebies and Bag-of-Specials methods of object detection during the detector training.\n",
    "\n",
    "3. Modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **::Related Work::**\n",
    "\n",
    "#### **1. Modern Detector**\n",
    "Usually composed of two parts.\n",
    "- ***Backbone*** pre-trained on ImageNet.\n",
    "- ***Head*** used to **predict classes** and **bounding boxes** of objects.\n",
    "\n",
    "#### **2. Backbones**\n",
    "\n",
    "Backbones can be classified according to platform(GPU, CPU)\n",
    "\n",
    "**Backbones on GPU Platform**\n",
    "\n",
    "- VGG [68]\n",
    "- ResNet [26]\n",
    "- ResNeXt [86]\n",
    "- DenseNet [30]\n",
    "\n",
    "**Backbones on CPU Platform**\n",
    "\n",
    "- SqueezeNet [31]\n",
    "- MobileNet [28, 66, 27, 74]\n",
    "- ShuffleNet [97, 53]\n",
    "\n",
    "#### **3. Head**\n",
    "\n",
    "As to the head part, it is usually categorized into two kinds(**one-stage** object detector, **two-stage** object detector)\n",
    "\n",
    "The representative object detectors are below.\n",
    "\n",
    "\n",
    "**Two-Stage-Detector**\n",
    "\n",
    "- R-CNN [19] series: fast R-CNN [18], faster R-CNN [64], R-FCN [9]\n",
    "- Libra R-CNN [58]\n",
    "\n",
    "**Two-Stage-Detector with anchor-free**\n",
    "- RepPoints [87]\n",
    "\n",
    "\n",
    "**One-Stage-Detector**\n",
    "\n",
    "- YOLO\n",
    "- SSD\n",
    "- RetinaNet\n",
    "\n",
    "**One-Stage-Detector with anchor-free**\n",
    "- CenterNet [13]\n",
    "- CornerNet [37, 38]\n",
    "- FCOS [78]\n",
    "\n",
    "#### **4. Neck**\n",
    "\n",
    "Recently Object Detectors inserting some layers between backbone and head are developed. \n",
    "\n",
    "These layers are usually used to collect feature maps from different stages\n",
    "\n",
    "Usually, a neck is composed of several **bottom-up paths** and several **topdown paths**. \n",
    "\n",
    "Networks equipped with this mechanism are below.\n",
    "\n",
    "- Feature Pyramid Network (FPN) [44]\n",
    "- Path Aggregation Network (PAN) [49]\n",
    "- BiFPN [77]\n",
    "- NAS-FPN [17]\n",
    "\n",
    "#### **5. New Backbone**\n",
    "\n",
    "In addition to the above models, some researchers put their emphasis on directly building a new backbone\n",
    "- DetNet [43]\n",
    "- DetNAS [7] \n",
    "\n",
    "#### **6. Whole New Model**\n",
    "- SpineNet [12]\n",
    "- HitDetector [20]\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8574845d26991fb924b9b73a047d47daa16a02e6e1ac35bb3c12f8621974ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('buddhalight3.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
