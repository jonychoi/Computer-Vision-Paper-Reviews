{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization**\n",
    "\n",
    "**Authors: Xun Huang, Serge Belongie - Department of Computer Science & Cornell Tech, Cornell University, {xh258,sjb344}@cornell.edu**\n",
    "\n",
    "**Official Github**: https://github.com/xunhuang1995/AdaIN-style\n",
    "\n",
    "**Original Paper**: https://arxiv.org/pdf/1703.06868.pdf\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 16 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Abstract**\n",
    "\n",
    "\n",
    "<p><i>Gatys et al. recently introduced a neural algorithm that\n",
    "renders a content image in the style of another image,\n",
    "achieving so-called style transfer. However, their framework requires a slow iterative optimization process, which\n",
    "limits its practical application. Fast approximations with\n",
    "feed-forward neural networks have been proposed to speed\n",
    "up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed\n",
    "set of styles and cannot adapt to arbitrary new styles. In this\n",
    "paper, we present a simple yet effective approach that for the\n",
    "first time enables arbitrary style transfer in real-time. At the\n",
    "heart of our method is a novel adaptive instance normalization (AdaIN) layer that aligns the mean and variance of the\n",
    "content features with those of the style features. Our method\n",
    "achieves speed comparable to the fastest existing approach,\n",
    "without the restriction to a pre-defined set of styles. In addition, our approach allows flexible user controls such as\n",
    "content-style trade-off, style interpolation, color & spatial\n",
    "controls, all using a single feed-forward neural network.\n",
    "</i>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Introduction**\n",
    "<p>\n",
    "The seminal work of Gatys et al. [16] showed that deep\n",
    "neural networks (DNNs) encode not only the content but\n",
    "also the style information of an image. Moreover, the image style and content are somewhat separable: it is possible\n",
    "to change the style of an image while preserving its content. The style transfer method of [16] is flexible enough to\n",
    "combine content and style of arbitrary images. However, it\n",
    "relies on an optimization process that is prohibitively slow.\n",
    "</p>\n",
    "<p>\n",
    "Significant effort has been devoted to accelerating neural\n",
    "style transfer. [24, 51, 31] attempted to train feed-forward\n",
    "neural networks that perform stylization with a single forward pass. A major limitation of most feed-forward methods is that each network is restricted to a single style. There\n",
    "are some recent works addressing this problem, but they are\n",
    "either still limited to a finite set of styles [11, 32, 55, 5], or\n",
    "much slower than the single-style transfer methods [6].\n",
    "</p>\n",
    "<p>\n",
    "    In this work, we present the first neural style transfer\n",
    "algorithm that resolves this fundamental flexibility-speed\n",
    "dilemma. Our approach can transfer arbitrary new styles\n",
    "in real-time, combining the flexibility of the optimizationbased framework [16] and the speed similar to the fastest\n",
    "feed-forward approaches [24, 52]. Our method is inspired\n",
    "by the instance normalization (IN) [52, 11] layer, which\n",
    "is surprisingly effective in feed-forward style transfer. To\n",
    "explain the success of instance normalization, we propose\n",
    "a new interpretation that instance normalization performs\n",
    "style normalization by normalizing feature statistics, which\n",
    "have been found to carry the style information of an image [16, 30, 33]. Motivated by our interpretation, we introduce a simple extension to IN, namely adaptive instance\n",
    "normalization (AdaIN). Given a content input and a style\n",
    "input, AdaIN simply adjusts the mean and variance of the\n",
    "content input to match those of the style input. Through\n",
    "experiments, we find AdaIN effectively combines the content of the former and the style latter by transferring feature\n",
    "statistics. A decoder network is then learned to generate the\n",
    "final stylized image by inverting the AdaIN output back to\n",
    "the image space. Our method is nearly three orders of magnitude faster than [16], without sacrificing the flexibility of\n",
    "transferring inputs to arbitrary new styles. Furthermore, our\n",
    "approach provides abundant user controls at runtime, without any modification to the training process.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Related Work**\n",
    "\n",
    "<p><strong>Style transfer.</strong> The problem of style transfer has its origin\n",
    "from non-photo-realistic rendering [28], and is closely related to texture synthesis and transfer [13, 12, 14]. Some\n",
    "early approaches include histogram matching on linear filter responses [19] and non-parametric sampling [12, 15].\n",
    "These methods typically rely on low-level statistics and often fail to capture semantic structures. Gatys et al. [16] for\n",
    "the first time demonstrated impressive style transfer results\n",
    "by matching feature statistics in convolutional layers of a\n",
    "DNN. Recently, several improvements to [16] have been\n",
    "proposed. Li and Wand [30] introduced a framework based\n",
    "on markov random field (MRF) in the deep feature space to\n",
    "enforce local patterns. Gatys et al. [17] proposed ways to\n",
    "control the color preservation, the spatial location, and the\n",
    "scale of style transfer. Ruder et al. [45] improved the quality of video style transfer by imposing temporal constraints.\n",
    "</p>\n",
    "<p>\n",
    "The framework of Gatys et al. [16] is based on a slow\n",
    "optimization process that iteratively updates the image to\n",
    "minimize a content loss and a style loss computed by a loss\n",
    "network. It can take minutes to converge even with modern GPUs. On-device processing in mobile applications is\n",
    "therefore too slow to be practical. A common workaround\n",
    "is to replace the optimization process with a feed-forward\n",
    "neural network that is trained to minimize the same objective [24, 51, 31]. These feed-forward style transfer approaches are about three orders of magnitude faster than\n",
    "the optimization-based alternative, opening the door to realtime applications. Wang et al. [53] enhanced the granularity\n",
    "of feed-forward style transfer with a multi-resolution architecture. Ulyanov et al. [52] proposed ways to improve the\n",
    "quality and diversity of the generated samples. However,\n",
    "the above feed-forward methods are limited in the sense that\n",
    "each network is tied to a fixed style. To address this problem, Dumoulin et al. [11] introduced a single network that\n",
    "is able to encode 32 styles and their interpolations. Concurrent to our work, Li et al. [32] proposed a feed-forward\n",
    "architecture that can synthesize up to 300 textures and transfer 16 styles. Still, the two methods above cannot adapt to\n",
    "arbitrary styles that are not observed during training.\n",
    "</p>\n",
    "<p>\n",
    "Very recently, Chen and Schmidt [6] introduced a feedforward method that can transfer arbitrary styles thanks to\n",
    "a style swap layer. Given feature activations of the content\n",
    "and style images, the style swap layer replaces the content\n",
    "features with the closest-matching style features in a patchby-patch manner. Nevertheless, their style swap layer creates a new computational bottleneck: more than 95% of the\n",
    "computation is spent on the style swap for 512 Ã— 512 input\n",
    "images. Our approach also permits arbitrary style transfer,\n",
    "while being 1-2 orders of magnitude faster than [6].\n",
    "</p>\n",
    "<p>\n",
    "    while being 1-2 orders of magnitude faster than [6].\n",
    "Another central problem in style transfer is which style\n",
    "loss function to use. The original framework of Gatys et\n",
    "al. [16] matches styles by matching the second-order statistics between feature activations, captured by the Gram matrix. Other effective loss functions have been proposed,\n",
    "such as MRF loss [30], adversarial loss [31], histogram\n",
    "loss [54], CORAL loss [41], MMD loss [33], and distance\n",
    "between channel-wise mean and variance [33]. Note that all\n",
    "the above loss functions aim to match some feature statistics\n",
    "between the style image and the synthesized image.\n",
    "</p>\n",
    "<p>\n",
    "<strong>Deep generative image modeling.</strong> There are several alternative frameworks for image generation, including variational auto-encoders [27], auto-regressive models [40], and\n",
    "generative adversarial networks (GANs) [18]. Remarkably,\n",
    "GANs have achieved the most impressive visual quality.\n",
    "Various improvements to the GAN framework have been\n",
    "proposed, such as conditional generation [43, 23], multistage processing [9, 20], and better training objectives [46,\n",
    "1]. GANs have also been applied to style transfer [31] and cross-domain image generation [50, 3, 23, 38, 37, 25].\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Background**\n",
    "\n",
    "#### 3.1. Batch Normalization\n",
    "\n",
    "<p>\n",
    "The seminal work of Ioffe and Szegedy [22] introduced\n",
    "a batch normalization (BN) layer that significantly ease the\n",
    "training of feed-forward networks by normalizing feature\n",
    "statistics. BN layers are originally designed to accelerate training of discriminative networks, but have also been\n",
    "found effective in generative image modeling [42]. Given\n",
    "an input batch x âˆˆ R\n",
    "NÃ—CÃ—HÃ—W , BN normalizes the mean\n",
    "and standard deviation for each individual feature channel:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('buddhalight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
