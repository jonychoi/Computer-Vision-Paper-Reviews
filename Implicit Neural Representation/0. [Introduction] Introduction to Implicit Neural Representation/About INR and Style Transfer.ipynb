{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **About INR and Style Transfer: the ulitmate purpose of style transfer within INR, by introducing its background and papers**\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 16 2022\n",
    "\n",
    "---\n",
    "\n",
    "Here, I wrote the writing contains about the *\"what are Implicit Neural Representations'*, the basic concept of INR, and its potential usage and applications. With the understanding of INR, I introduced the its representative papers within few couples of years to apprehend its trend and evolution history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overview**\n",
    "\n",
    "**1. The Goal of the Writing**\n",
    "\n",
    "**2. What are Implicit Neural Representations**\n",
    "\n",
    "**3. The applications and potentials of INR**\n",
    "\n",
    "**4. Latest Trend of INR**\n",
    "\n",
    "**5. About Style Transfer**\n",
    "\n",
    "**6. What Style Transfer ultimately purpose**\n",
    "\n",
    "**7. Reviews about representative paper related to Style Transfer**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. The Goal of the Writing**\n",
    "\n",
    "Here, as a beginner of *Style Transfer* within *INR(Implicit Neural Representation)* field, I'm going to introduce what are implict neural representations and style transfer with its *basic concept* and *the usages with the potential applicablity*, by *reviewing the core papers* that enhance understanding of Style Transfer within INR field.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. What are Implicit Neural Representations?**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Implicit neural representations**\n",
    "\n",
    "***\"Implicit neural representations is about parameterizing a continuous differentiable signal with a neural network. The signal is encoded within the neural network, providing a possibly more compact representation.*** *This is a type of [regression](https://hugocisneros.com/notes/machine_learning/) problem. Applications of these learned representations range from simple [compression](https://hugocisneros.com/notes/compression/), to 3D scene reconstruction from 2D images, semantic information inference, etc.[CPPN](https://hugocisneros.com/notes/cppn/) is an early example of a implicit neural representation implementation mainly used for pattern generation. It uses a neural network to generate patterns parameterized by two (or more) coordinates.\"*\n",
    "\n",
    "***by [Hugo Cisneros](https://hugocisneros.com/notes/implicit_neural_representations/#org36a6837)***\n",
    "\n",
    "***\"Implicit Neural Representations (sometimes also referred to as coordinate-based representations) are a novel way to parameterize signals of all kinds.*** Conventional signal representations are usually discrete - *for instance, images are discrete grids of pixels, audio signals are discrete samples of amplitudes, and 3D shapes are usually parameterized as grids of voxels, point clouds, or meshes. In contrast, Implicit Neural Representations parameterize a signal as a ***continuous function*** that maps the domain of the signal (i.e., a coordinate, such as a pixel coordinate for an image) to whatever is at that coordinate (for an image, an R,G,B color). Of course, these functions are usually not analytically tractable - it is impossible to \"write down\" the function that parameterizes a natural image as a mathematical formula. Implicit Neural Representations thus approximate that function via a neural network.\"*\n",
    "\n",
    "***by [Vincent Sitzman](https://github.com/vsitzmann/awesome-implicit-representations#what-are-implicit-neural-representations)***\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why are they interesting?**\n",
    "\n",
    "Implicit Neural Representations have several benefits: First, they are not coupled to spatial resolution anymore, the way, for instance, an image is coupled to the number of pixels. This is because they are continuous functions! Thus, the memory required to parameterize the signal is independent of spatial resolution, and only scales with the complexity of the underyling signal. Another corollary of this is that implicit representations have \"infinite resolution\" - they can be sampled at arbitrary spatial resolutions.\n",
    "\n",
    "This is immediately useful for a number of applications, such as super-resolution, or in parameterizing signals in 3D and higher dimensions, where memory requirements grow intractably fast with spatial resolution. Further, generalizing across neural implicit representations amounts to learning a prior over a space of functions, implemented via learning a prior over the weights of neural networks - this is commonly referred to as meta-learning and is an extremely exciting intersection of two very active research areas! Another exciting overlap is between neural implicit representations and the study of symmetries in neural network architectures - for intance, creating a neural network architecture that is 3D rotation-equivariant immediately yields a viable path to rotation-equivariant generative models via neural implicit representations.\n",
    "\n",
    "Another key promise of implicit neural representations lie in algorithms that directly operate in the space of these representations. In other words: What's the \"convolutional neural network\" equivalent of a neural network operating on images represented by implicit representations?\n",
    "\n",
    "*Reference from [Vincent Sitzman](https://github.com/vsitzmann/awesome-implicit-representations#what-are-implicit-neural-representations)*\n",
    "\n",
    "---\n",
    "\n",
    "#### **Similar Fields related to INR**\n",
    "\n",
    "***Implicit neural representations for high frequency data***\n",
    "\n",
    "*To encode potentially high frequency data such as sound or images, it is much more efficient to start from periodic feature transformations. This can be achieved with periodic activation functions [(Sitzmann et al. 2020)](https://arxiv.org/abs/2006.09661) or by using a Fourier feature mapping [(Tancik et al. 2020)](https://arxiv.org/abs/2006.10739).*\n",
    "\n",
    "***Neural radiance fields***\n",
    "\n",
    "[(Mildenhall et al. 2020)](https://arxiv.org/abs/2003.08934)\n",
    "\n",
    "*Reference From [Hugo Cisneros](https://hugocisneros.com/notes/implicit_neural_representations/#org36a6837)*\n",
    "\n",
    "---\n",
    "\n",
    "#### **Here's my thought.**\n",
    "\n",
    "***The Implicit Neural Representation*** *is a full kinds of* ***mapping function***, *that identifying a specific pattern from existing phenomena and maps to an unspecified object.*\n",
    "\n",
    "*It contains various models of Deep Learning fields, especially the Generative Adversarial Networks are frequently used to construct the function nowadays, previously many approaches suggested such as statistical methods since its purpose is encoding the potential frequency as much as possible from the original phenomenon that can appear.*\n",
    "\n",
    "*One of the difference between* ***Traditional Explicit Representations*** *and* ***Implicit Neural Representation*** *is whether* ***discrete*** *or* ***contionus***, *which its property of 'continous' better represents the kind of mapping function, a distribution sampled from the existing distribution.*\n",
    "\n",
    "*The Deep Learning, which contains the huge amount of* ***techiniques to map the specific function*** *including MLP, CNN, Encoder-Decoder architecture are* ***can be seen in the same context.***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. The applications and potentials of INR**\n",
    "\n",
    "There are huge usages and applicable stuffs with the Implicit Neural Representation. \n",
    "**Due to the property of Implicit Encoding that mapping the meaningful new distribution from the actual space**, It can be applicable to various domains through implicit encoding and has the advantage of being able to largerly expandable from a specific domain to various scales.\n",
    "\n",
    "One of the most applicable field with INR is Image to Image Translation. Image-to-image translation is called 'I2I' as a abbreviation, the I2I is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image. It can be applied to a wide range of applications, such as collection style transfer, object transfiguration, season transfer and photo enhancement. Briefly, Image to Image Translation takes a task of taking images from one domain and transforming them so they have the style (or characteristics) of images from another domain. Here's some example.\n",
    "\n",
    "##### **CycleGAN**\n",
    "\n",
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <img src=\"https://miro.medium.com/max/1050/0*Udvw6tGu40iDEkuH.jpg\" width=\"200\" />\n",
    "            </td>\n",
    "            <td>\n",
    "                <i><strong>Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks(ICCV 2017)</strong></i>\n",
    "                Author presents an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. The goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to enforce F(G(X)) ≈ X (and vice versa).\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <img src=\"https://miro.medium.com/max/975/0*P-46iNsLcF2edVfn.png\" width=\"200\" />\n",
    "            </td>\n",
    "            <td>\n",
    "               Paired training data (left) consists of training examples have one to one correspondence. Unpaired training set has no such correspondence.\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "![](https://miro.medium.com/max/1050/0*KXiC6nIcowYS5GtA.png)\n",
    "\n",
    "The model contains two mapping functions G : X → Y and F : Y → X , and associated adversarial discriminators DY and DX . DY encourages G to translate X into outputs indistinguishable from domain Y , and vice versa for DX , F , and X . To further regularize the mappings, they introduce two “cycle consistency losses” that capture the intuition that if we translate from one domain to the other and back again we should arrive where we started.\n",
    "\n",
    "Reference: [Image-to-Image Translation](https://towardsdatascience.com/image-to-image-translation-69c10c18f6ff)\n",
    "\n",
    "Image generation\n",
    "\n",
    "3d reconstruction\n",
    "\n",
    "nerf\n",
    "\n",
    "here, style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Latest Trend of INR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. About Style Transfer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. What Style Transfer ultimately purpose**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Representative INR paper reviews**\n",
    "\n",
    "#### **1. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**\n",
    "> **Authors: Sergey Ioffe, Christian Szegedy - Google Inc., {sioffe, szegedy} @google.com**\n",
    "\n",
    "> **Original Paper**: https://arxiv.org/pdf/1502.03167.pdf\n",
    "\n",
    "> **Un official Github**: https://github.com/shuuki4/Batch-Normalization\n",
    "\n",
    "#### **2. Instance Normalization: The Missing Ingredient for Fast Stylization**\n",
    "\n",
    "> **Authors: Dmitry Ulyanov [dmitry.ulyanov@skoltech.ru], Andrea Vedaldi [vedaldi@robots.ox.ac.uk], Victor Lempitsky [lempitsky@skoltech.ru]**\n",
    "\n",
    "> **Original Paper**: https://arxiv.org/pdf/1607.08022.pdf\n",
    "\n",
    "> **Official Github**: https://github.com/DmitryUlyanov/texture_nets\n",
    "\n",
    "#### 3. **Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization**\n",
    "\n",
    "> **Authors: Xun Huang, Serge Belongie - Department of Computer Science & Cornell Tech, Cornell University, {xh258,sjb344}@cornell.edu**\n",
    "\n",
    "> **Official Github**: https://github.com/xunhuang1995/AdaIN-style\n",
    "\n",
    "> **Original Paper**: https://arxiv.org/pdf/1703.06868.pdf\n",
    "\n",
    "#### **4. Semantic Image Synthesis with Spatially-Adaptive Normalization**\n",
    "\n",
    "> **Authors: Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan ZhuL**\n",
    "\n",
    "> **Original Paper**: https://arxiv.org/pdf/1903.07291.pdf\n",
    "\n",
    "> **Official Github**: https://github.com/NVlabs/SPADE\n",
    "\n",
    "#### **5. Universal Style Transfer via Feature Transforms**\n",
    "\n",
    "> **Authors: Yijun Li\n",
    "(UC Merced -\n",
    "yli62@ucmerced.edu),\n",
    "Chen Fang\n",
    "(Adobe Research - \n",
    "cfang@adobe.com)\n",
    "Jimei Yang\n",
    "(Adobe Research -\n",
    "jimyang@adobe.com)\n",
    "Zhaowen Wang\n",
    "(Adobe Research - \n",
    "zhawang@adobe.com)\n",
    "Xin Lu\n",
    "(Adobe Research - \n",
    "xinl@adobe.com)\n",
    "Ming-Hsuan Yang\n",
    "(UC Merced, NVIDIA Research - \n",
    "mhyang@ucmerced.edu)**\n",
    "\n",
    "> **Original Paper**: https://arxiv.org/pdf/1705.08086.pdf\n",
    "\n",
    "> **Official Github**: https://github.com/Yijunmaverick/UniversalStyleTransfer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Why Internal Covariance Shift Matters?**\n",
    "\n",
    "At the first when I encounter the *'Normalization'* term in INR (Implicit Neural Representation) Field, I thought it is just a one of the common technique(at least the current point of Jan, 2022) to enhance the deep learning models' performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift**\n",
    "\n",
    "**Overview**\n",
    "\n",
    "The paper suggest the three main things that enhance the neural networks' performance by using the one of the technique called 'Batch Normalization', and the suggested benefits are below.\n",
    "\n",
    "1. Allow to use higher learning rate\n",
    "2. Allow to be less careful about initializations\n",
    "3. Acting as a regularizer, in some cases eliminating the needs of Dropout\n",
    "4. When using a nonlinear function (such as sigmoid), it prevents falling into the saturated region (where the slope is zero). Therefore, it prevents slope loss and saturation problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presented Previous Problem**\n",
    "\n",
    "With using SGD(Mini-Batch Stochastic Gradient Descent), it is good algorithm to train the network, however there are several problems.\n",
    "\n",
    "1. It requires careful tuning of the model **hyper-parameters**, specifically the ***learning rate*** used in optimization, as well as the inital values for the ***model parameters***.\n",
    "\n",
    "2. The change in the distributions of layers' input presents a problem because the layers need to continuosly adapt to the new distribution.\n",
    "\n",
    "*When the input distribution to a learning system changes, it is is said to experience* ***Covariance Shift***.\n",
    "\n",
    "> This is typically handled via domain adaption. However, the notion of covariate shift can be extended beyond the learning system as a whole, to apply its parts, such as a sub-network or a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contribution**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('buddhalight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
