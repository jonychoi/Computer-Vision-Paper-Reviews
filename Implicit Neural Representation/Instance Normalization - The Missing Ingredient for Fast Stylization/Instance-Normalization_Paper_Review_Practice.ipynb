{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instance Normalization: The Missing Ingredient for Fast Stylization**\n",
    "\n",
    "**Authors: Dmitry Ulyanov [dmitry.ulyanov@skoltech.ru], Andrea Vedaldi [vedaldi@robots.ox.ac.uk], Victor Lempitsky [lempitsky@skoltech.ru]**\n",
    "\n",
    "**Original Paper**: https://arxiv.org/pdf/1607.08022.pdf\n",
    "\n",
    "**Official Github**: https://github.com/DmitryUlyanov/texture_nets\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 15 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Abstract**\n",
    "\n",
    "It this paper we revisit the fast stylization method introduced in Ulyanov et al.\n",
    "(2016). We show how a small change in the stylization architecture results in a\n",
    "significant qualitative improvement in the generated images. The change is limited to swapping batch normalization with instance normalization, and to apply\n",
    "the latter both at training and testing times. The resulting method can be used to\n",
    "train high-performance architectures for real-time image generation. The code is\n",
    "available at https://github.com/DmitryUlyanov/texture_nets. Full paper can be found at https://arxiv.org/abs/1701.02096."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 Introduction**\n",
    "<p>\n",
    "The recent work of Gatys et al. (2016) introduced a method for transferring a style from an image\n",
    "onto another one, as demonstrated in fig. 1. The stylized image matches simultaneously selected\n",
    "statistics of the style image and of the content image. Both style and content statistics are obtained\n",
    "from a deep convolutional network pre-trained for image classification. The style statistics are extracted from shallower layers and averaged across spatial locations whereas the content statistics are\n",
    "extracted form deeper layers and preserve spatial information. In this manner, the style statistics\n",
    "capture the “texture” of the style image whereas the content statistics capture the “structure” of the\n",
    "content image.\n",
    "</p>\n",
    "<p>\n",
    "Although the method of Gatys et. al produces remarkably good results, it is computationally inefficient. The stylized image is, in fact, obtained by iterative optimization until it matches the desired\n",
    "statistics. In practice, it takes several minutes to stylize an image of size 512 × 512. Two recent\n",
    "works, Ulyanov et al. (2016) Johnson et al. (2016), sought to address this problem by learning\n",
    "equivalent feed-forward generator networks that can generate the stylized image in a single pass.\n",
    "These two methods differ mainly by the details of the generator architecture and produce results of\n",
    "a comparable quality; however, neither achieved as good results as the slower optimization-based\n",
    "method of Gatys et. al.\n",
    "</p>\n",
    "<img src=\"./imgs/figure1.png\" />\n",
    "<img src=\"./imgs/figure2.png\" />\n",
    "<p>\n",
    "In this paper we revisit the method for feed-forward stylization of Ulyanov et al. (2016) and show\n",
    "that a small change in a generator architecture leads to much improved results. The results are in\n",
    "fact of comparable quality as the slow optimization method of Gatys et al. but can be obtained in\n",
    "real time on standard GPU hardware. The key idea (section 2) is to replace batch normalization layers in the generator architecture with instance normalization layers, and to keep them at test\n",
    "time (as opposed to freeze and simplify them out as done for batch normalization). Intuitively,\n",
    "the normalization process allows to remove instance-specific contrast information from the content\n",
    "image, which simplifies generation. In practice, this results in vastly improved images (section 3).\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8574845d26991fb924b9b73a047d47daa16a02e6e1ac35bb3c12f8621974ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('buddhalight3.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
