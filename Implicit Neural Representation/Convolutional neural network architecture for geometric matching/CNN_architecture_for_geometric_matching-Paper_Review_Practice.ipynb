{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Convolutional neural network architecture for geometric matching**\n",
    "\n",
    "**Authors: Ignacio Rocco  (IDI), Relja Arandjelovic (ENS), Josef Sivic (3CIIRC)**\n",
    "\n",
    "**Official Github**: https://github.com/ignacio-rocco/cnngeometric_pytorch\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 10 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Abstract**\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>\n",
    "                Abstract\n",
    "            </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <i>\n",
    "                    We address the problem of determining correspondences\n",
    "                    between two images in agreement with a geometric model\n",
    "                    such as an affine or thin-plate spline transformation, and\n",
    "                    estimating its parameters. The contributions of this work\n",
    "                    are three-fold. First, we propose a convolutional neural network architecture for geometric matching. The architecture\n",
    "                    is based on three main components that mimic the standard\n",
    "                    steps of feature extraction, matching and simultaneous inlier detection and model parameter estimation, while being\n",
    "                    trainable end-to-end. Second, we demonstrate that the network parameters can be trained from synthetically generated imagery without the need for manual annotation and\n",
    "                    that our matching layer significantly increases generalization capabilities to never seen before images. Finally, we\n",
    "                    show that the same model can perform both instance-level\n",
    "                    and category-level matching giving state-of-the-art results\n",
    "                    on the challenging Proposal Flow dataset.\n",
    "                </i>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Introduction**\n",
    "\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>\n",
    "                Introduction\n",
    "            </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>\n",
    "                    Estimating correspondences between images is one of\n",
    "                    the fundamental problems in computer vision [19, 25] with\n",
    "                    applications ranging from large-scale 3D reconstruction [3]\n",
    "                    to image manipulation [21] and semantic segmentation\n",
    "                    [42]. Traditionally, correspondences consistent with a geometric model such as epipolar geometry or planar affine\n",
    "                    transformation, are computed by detecting and matching\n",
    "                    local features (such as SIFT [38] or HOG [12, 22]), followed by pruning incorrect matches using local geometric\n",
    "                    constraints [43, 47] and robust estimation of a global geometric transformation using algorithms such as RANSAC\n",
    "                    [18] or Hough transform [32, 34, 38]. This approach works\n",
    "                    well in many cases but fails in situations that exhibit (i) large\n",
    "                    changes of depicted appearance due to e.g. intra-class variation [22], or (ii) large changes of scene layout or non-rigid deformations that require complex geometric models with\n",
    "                    many parameters which are hard to estimate in a manner\n",
    "                    robust to outliers.\n",
    "                </p>\n",
    "                <table>\n",
    "                    <tbody>\n",
    "                        <tr>\n",
    "                            <td>\n",
    "                                <img src=\"./imgs/figure1.png\" width=\"550px\" />\n",
    "                            </td>\n",
    "                            <td>\n",
    "                                Figure 1: Our trained geometry estimation network automatically\n",
    "                                aligns two images with substantial appearance differences. It is\n",
    "                                able to estimate large deformable transformations robustly in the\n",
    "                                presence of clutter.\n",
    "                            </td>\n",
    "                        </tr>\n",
    "                    </tbody>\n",
    "                </table>\n",
    "                <p>\n",
    "                    In this work we build on the traditional approach and\n",
    "                    develop a convolutional neural network (CNN) architecture\n",
    "                    that mimics the standard matching process. First, we replace the standard local features with powerful trainable\n",
    "                    convolutional neural network features [31, 46], which allows us to handle large changes of appearance between\n",
    "                    the matched images. Second, we develop trainable matching and transformation estimation layers that can cope with\n",
    "                    noisy and incorrect matches in a robust way, mimicking the\n",
    "                    good practices in feature matching such as the second nearest neighbor test [38], neighborhood consensus [43, 47] and\n",
    "                    Hough transform-like estimation [32, 34, 38].\n",
    "                </p>\n",
    "                <p>\n",
    "                    The outcome is a convolutional neural network architecture trainable for the end task of geometric matching,\n",
    "                    which can handle large appearance changes, and is therefore\n",
    "                    suitable for both instance-level and category-level matching\n",
    "                    problems.\n",
    "                </p>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Related Work**\n",
    "\n",
    "The classical approach for finding correspondences involves identifying interest points and computing local descriptors around these points [10, 11, 24, 37, 38, 39, 43].\n",
    "6148\n",
    "While this approach performs relatively well for instancelevel matching, the feature detectors and descriptors lack\n",
    "the generalization ability for category-level matching.\n",
    "\n",
    "Recently, convolutional neural networks have been used\n",
    "to learn powerful feature descriptors which are more robust\n",
    "to appearance changes than the classical descriptors [9, 23,\n",
    "28, 45, 52]. However, these works still divide the image into\n",
    "a set of local patches and extract a descriptor individually\n",
    "from each patch. Extracted descriptors are then compared\n",
    "with an appropriate distance measure [9, 28, 45], by directly\n",
    "outputting a similarity score [23, 52], or even by directly\n",
    "outputting a binary matching/non-matching decision [4].\n",
    "\n",
    "In this work, we take a different approach, treating the\n",
    "image as a whole, instead of a set of patches. Our approach\n",
    "has the advantage of capturing the interaction of the different parts of the image in a greater extent, which is not possible when the image is divided into a set of local regions.\n",
    "\n",
    "Related are also network architectures for estimating\n",
    "inter-frame motion in video [17, 48, 50] or instance-level\n",
    "homography estimation [14], however their goal is very different from ours, targeting high-precision correspondence\n",
    "with very limited appearance variation and background\n",
    "clutter. Closer to us is the network architecture of [29]\n",
    "which, however, tackles a different problem of fine-grained\n",
    "category-level matching (different species of birds) with\n",
    "limited background clutter and small translations and scale\n",
    "changes, as their objects are largely centered in the image.\n",
    "In addition, their architecture is based on a different matching layer, which we show not to perform as well as the\n",
    "matching layer used in our work.\n",
    "\n",
    "Some works, such as [11, 15, 22, 30, 35, 36], have addressed the hard problem of category-level matching, but\n",
    "rely on traditional non-trainable optimization for matching\n",
    "[11, 15, 30, 35, 36], or guide the matching using object proposals [22]. On the contrary, our approach is fully trainable\n",
    "in an end-to-end manner and does not require any optimization procedure at evaluation time, or guidance by object proposals.\n",
    "\n",
    "Others [33, 44, 53] have addressed the problems of instance and category-level correspondence by performing\n",
    "joint image alignment. However, these methods differ from\n",
    "ours as they: (i) require class labels; (ii) don’t use CNN features; (iii) jointly align a large set of images, while we align\n",
    "image pairs; and (iv) don’t use a trainable CNN architecture\n",
    "for alignment as we do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8574845d26991fb924b9b73a047d47daa16a02e6e1ac35bb3c12f8621974ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('buddhalight3.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
