{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PointRend - Image Segmentation as Rendering**\n",
    "\n",
    "**Authors: Alexander Kirillov, Yuxin Wu, Kaiming H,e Ross Girshick - Facebook AI Research (FAIR)**\n",
    "\n",
    "**Official Github**: https://github.com/facebookresearch/detectron2/tree/main/projects/PointRend\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 10 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Abstract**\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <strong>Abstract</strong>\n",
    "    </td>\n",
    "    <td>\n",
    "      <strong>Key Summary</strong>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td width=\"400\">\n",
    "        *We present a new method for efficient high-quality\n",
    "        image segmentation of objects and scenes. By analogizing\n",
    "        classical computer graphics methods for efficient rendering\n",
    "        with over- and undersampling challenges faced in pixel\n",
    "        labeling tasks, we develop a unique perspective of image\n",
    "        segmentation as a rendering problem. From this vantage,\n",
    "        we present the PointRend (Point-based Rendering) neural\n",
    "        network module: a module that performs point-based\n",
    "        segmentation predictions at adaptively selected locations\n",
    "        based on an iterative subdivision algorithm. PointRend\n",
    "        can be flexibly applied to both instance and semantic\n",
    "        segmentation tasks by building on top of existing state-ofthe-art models. While many concrete implementations of\n",
    "        the general idea are possible, we show that a simple design\n",
    "        already achieves excellent results. Qualitatively, PointRend\n",
    "        outputs crisp object boundaries in regions that are oversmoothed by previous methods. Quantitatively, PointRend\n",
    "        yields significant gains on COCO and Cityscapes, for both\n",
    "        instance and semantic segmentation. PointRend’s efficiency\n",
    "        enables output resolutions that are otherwise impractical\n",
    "        in terms of memory or computation compared to existing\n",
    "        approaches. Code has been made available at https://\n",
    "        github.com/facebookresearch/detectron2/\n",
    "        tree/master/projects/PointRend.*\n",
    "      </td>\n",
    "      <td valign=\"top\" width=\"600\">\n",
    "        <strong>Figure 1: Instance segmentation with PointRend.</strong>\n",
    "        We introduce the PointRend (Point-based Rendering) module that makes predictions at adaptively sampled points on the image using a new pointbased feature representation (see Fig. 3). PointRend is general and\n",
    "        can be flexibly integrated into existing semantic and instance segmentation systems. When used to replace Mask R-CNN’s default\n",
    "        mask head [19] (top-left), PointRend yields significantly more detailed results (top-right). (bottom) During inference, PointRend iterative computes its prediction. Each step applies bilinear upsampling in smooth regions and makes higher resolution predictions\n",
    "        at a small number of adaptively selected points that are likely to\n",
    "        lie on object boundaries (black points). All figures in the paper are\n",
    "        best viewed digitally with zoom. Image source: [41].\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Abstract [Key Summary]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "Image segmentation tasks involve mapping pixels sampled on a regular grid to a label map, or a set of label maps,\n",
    "on the same grid. For semantic segmentation, the label map\n",
    "indicates the predicted category at each pixel. In the case of\n",
    "instance segmentation, a binary foreground vs. background\n",
    "map is predicted for each detected object. The modern tools\n",
    "of choice for these tasks are built on convolutional neural\n",
    "networks (CNNs) [27, 26].\n",
    "\n",
    "CNNs for image segmentation typically operate on regular grids: the input image is a regular grid of pixels, their\n",
    "hidden representations are feature vectors on a regular grid,\n",
    "and their outputs are label maps on a regular grid. Regular grids are convenient, but not necessarily computationally ideal for image segmentation. The label maps predicted by these networks should be mostly smooth, i.e.,\n",
    "neighboring pixels often take the same label, because highfrequency regions are restricted to the sparse boundaries between objects. A regular grid will unnecessarily oversample\n",
    "the smooth areas while simultaneously undersampling object boundaries. The result is excess computation in smooth\n",
    "regions and blurry contours (Fig. 1, upper-left). Image segmentation methods often predict labels on a low-resolution\n",
    "regular grid, e.g., 1/8-th of the input [35] for semantic segmentation, or 28×28 [19] for instance segmentation, as a\n",
    "compromise between undersampling and oversampling.\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "      <td>\n",
    "        <img src=\"./imgs/figure1.png\" width=\"350px\" />\n",
    "      </td>\n",
    "      <td valign=\"bottom\" width=\"700\">\n",
    "        <strong>Figure 1: Instance segmentation with PointRend.</strong>\n",
    "        We introduce the PointRend (Point-based Rendering) module that makes predictions at adaptively sampled points on the image using a new pointbased feature representation (see Fig. 3). PointRend is general and\n",
    "        can be flexibly integrated into existing semantic and instance segmentation systems. When used to replace Mask R-CNN’s default\n",
    "        mask head [19] (top-left), PointRend yields significantly more detailed results (top-right). (bottom) During inference, PointRend iterative computes its prediction. Each step applies bilinear upsampling in smooth regions and makes higher resolution predictions\n",
    "        at a small number of adaptively selected points that are likely to\n",
    "        lie on object boundaries (black points). All figures in the paper are\n",
    "        best viewed digitally with zoom. Image source: [41].\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "pic\n",
    "\n",
    "Analogous sampling issues have been studied for\n",
    "decades in computer graphics. For example, a renderer\n",
    "maps a model (e.g., a 3D mesh) to a rasterized image, i.e. a\n",
    "regular grid of pixels. While the output is on a regular grid,\n",
    "computation is not allocated uniformly over the grid. Instead, a common graphics strategy is to compute pixel values at an irregular subset of adaptively selected points in the\n",
    "image plane. The classical subdivision technique of [48], as\n",
    "an example, yields a quadtree-like sampling pattern that efficiently renders an anti-aliased, high-resolution image.\n",
    "\n",
    "The central idea of this paper is to view image segmentation as a rendering problem and to adapt classical\n",
    "ideas from computer graphics to efficiently “render” highquality label maps (see Fig. 1, bottom-left). We encapsulate this computational idea in a new neural network\n",
    "module, called PointRend, that uses a subdivision strategy\n",
    "to adaptively select a non-uniform set of points at which\n",
    "to compute labels. PointRend can be incorporated into\n",
    "popular meta-architectures for both instance segmentation\n",
    "(e.g., Mask R-CNN [19]) and semantic segmentation (e.g.,\n",
    "FCN [35]). Its subdivision strategy efficiently computes\n",
    "high-resolution segmentation maps using an order of magnitude fewer floating-point operations than direct, dense\n",
    "computation.\n",
    "\n",
    "PointRend is a general module that admits many possible implementations. Viewed abstractly, a PointRend\n",
    "module accepts one or more typical CNN feature maps\n",
    "f(xi\n",
    ", yi) that are defined over regular grids, and outputs\n",
    "high-resolution predictions p(x\n",
    "0\n",
    "i\n",
    ", y0\n",
    "i\n",
    ") over a finer grid. Instead of making excessive predictions over all points on the\n",
    "output grid, PointRend makes predictions only on carefully\n",
    "selected points. To make these predictions, it extracts a\n",
    "point-wise feature representation for the selected points by\n",
    "interpolating f, and uses a small point head subnetwork to\n",
    "predict output labels from the point-wise features. We will\n",
    "present a simple and effective PointRend implementation.\n",
    "\n",
    "We evaluate PointRend on instance and semantic segmentation tasks using the COCO [29] and Cityscapes [9]\n",
    "benchmarks. Qualitatively, PointRend efficiently computes\n",
    "sharp boundaries between objects, as illustrated in Fig. 2\n",
    "and Fig. 8. We also observe quantitative improvements even\n",
    "though the standard intersection-over-union based metrics\n",
    "for these tasks (mask AP and mIoU) are biased towards\n",
    "object-interior pixels and are relatively insensitive to boundary improvements. PointRend improves strong Mask RCNN and DeepLabV3 [5] models by a significant margin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8574845d26991fb924b9b73a047d47daa16a02e6e1ac35bb3c12f8621974ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('buddhalight3.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
