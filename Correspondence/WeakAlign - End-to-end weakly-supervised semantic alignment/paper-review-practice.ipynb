{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **End-to-end weakly-supervised semantic alignment**\n",
    "\n",
    "**Authors: Ignacio Rocco1,2, Relja Arandjelovic´3, Josef Sivic1,2,4**\n",
    "\n",
    "**1 DI ENS / 2 Inria / 3 DeepMind / 4 CIIRC, CTU in Prague**\n",
    "\n",
    "**[Official Github Code](https://github.com/ignacio-rocco/weakalign)** / **[Project Page](https://www.di.ens.fr/willow/research/weakalign/)** / **[Pdf](https://arxiv.org/abs/1712.06861)**\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews](https://github.com/jonychoi/Computer-Vision-Paper-Reviews)**\n",
    "\n",
    "Edited March 21 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Abstract**\n",
    "\n",
    "***\"We tackle the task of semantic alignment where the goal\n",
    "is to compute dense semantic correspondence aligning two\n",
    "images depicting objects of the same category.\"***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Contribution**\n",
    "\n",
    "---\n",
    "\n",
    "***First***, *we develop a convolutional neural network architecture for semantic alignment\n",
    "that is trainable in an end-to-end manner from weak imagelevel supervision in the form of matching image pairs.*\n",
    "\n",
    "> ***Semi-Local Constraints*를 이용하여 애매모한 Feature를 매칭시키는 클래식한 아이디어에서 영감을 얻은바, Global Gemoetric Model의 필요 없이, 4D Space에서 가능한 모든 neighbourhood consensus 패턴들을 분석해서 spatially matching하는, End-to-End로 학습가능한 CNN Architecture를 개발.**\n",
    "\n",
    "---\n",
    "\n",
    "***Second***, *the main component of this architecture is a differentiable soft inlier scoring module, inspired by the RANSAC inlier scoring procedure, that computes the quality of the alignment based on\n",
    "only geometrically consistent correspondences thereby reducing the effect of background clutter.*\n",
    "\n",
    "> **Manual annotation, 즉 완전 하드 annotated 방식이 아닌 matching과 non-matchinig image pairs 형태를 갖춘 weak supervision을 통해 효율적 학습**\n",
    "\n",
    "---\n",
    "\n",
    "***Third***, *we demonstrate that the proposed approach achieves state-of-the-art\n",
    "performance on multiple standard benchmarks for semantic\n",
    "alignment.*\n",
    "\n",
    "> **여기서는 정성적 평가. Neighbourhood Consensus Network는 Category, Instance-level Matching을 포함한 넓은 matching task에서 PF PASCAL 데이터셋과 InLoc Indoor Visual Localization 벤치마크에서 소타달성.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "![](https://www.di.ens.fr/willow/research/weakalign/images/teaser.jpg)\n",
    "\n",
    "> **기존의 Visual Correspondence는 *Viewpoint*의 변화나, *illumination* 등 다양한 variation에 꽤 괜찮은 결과를 낳았으나, 여전히 hand crafted 모델에 비해서 trainable한 모델들이 근소하게 좋은 성능을 보이고 있음. (OD나 Classification과 다르게)**\n",
    "\n",
    "*\"One of the reasons for this plateauing performance could be the currently dominant approach for\n",
    "finding image correspondence based on matching individual image features. While we have now better\n",
    "local patch descriptors, the matching is still performed by variants of the nearest neighbour assignment\n",
    "in a feature space followed by separate disambiguation stages based on geometric constraints.\"*\n",
    "\n",
    "> **애매모하고 variate한 feature들 분리하고, invariate한 부분들 위주로 가장 가까운 neighbour을 갖다가 assign해버리는 individual image feature 기반의 image correspondence 가 dominant한 approach.**\n",
    "\n",
    "*\"This\n",
    "approach has, however, fundamental limitations. Imagine a scene with textureless regions or repetitive\n",
    "patterns, such as a corridor with almost textureless walls and only few distinguishing features. A\n",
    "small patch of an image, depicting a repetitive pattern or a textureless area, is indistinguishable from other portions of the image depicting the same repetitive or textureless pattern. Such matches will be\n",
    "either discarded [23] or incorrect. As a result, matching individual patch descriptors will often fail in\n",
    "such challenging situations.\"*\n",
    "\n",
    "> **그러나 이건 근본적인 문제점. Textureless한 region 또는 반복되는 패턴의 회랑 같은 것들은 조금의 분류가능한 feature들을 가지고 있음. 때문에 이러한 Individual한 patch descriptors는 이러한 challenging한 상황에서 실패**\n",
    "\n",
    "\n",
    "*\"In this work we take a different direction and develop a trainable neural network architecture that\n",
    "disambiguates such challenging situations by analyzing local neighbourhood patterns in a full set of\n",
    "dense correspondences. **The intuition is the following: in order to disambiguate a match on a repetitive\n",
    "pattern, it is necessary to analyze a larger context of the scene that contains a unique non-repetitive\n",
    "feature.** The information from this unique match can then be propagated to the neighbouring uncertain\n",
    "matches. **In other words, the certain unique matches will support the close-by uncertain ambiguous\n",
    "matches in the image.\"***\n",
    "\n",
    "> **그래서 큰 Context에서 Unique한 것들이 가까운 애매모한 것들을 Matching하는 걸 support함으로써 uncertain한 것들을 처리하자!! + trainable CNN은 당연하고**\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('buddhalight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
