{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **End-to-end weakly-supervised semantic alignment**\n",
    "\n",
    "**Authors: Ignacio Rocco1,2, Relja Arandjelovic´3, Josef Sivic1,2,4**\n",
    "\n",
    "**1 DI ENS / 2 Inria / 3 DeepMind / 4 CIIRC, CTU in Prague**\n",
    "\n",
    "**[Official Github Code](https://github.com/ignacio-rocco/weakalign)** / **[Project Page](https://www.di.ens.fr/willow/research/weakalign/)** / **[Pdf](https://arxiv.org/abs/1712.06861)**\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews](https://github.com/jonychoi/Computer-Vision-Paper-Reviews)**\n",
    "\n",
    "Edited March 21 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary**\n",
    "\n",
    "This is a\n",
    "challenging task due to large intra-class variation, changes\n",
    "in viewpoint and background clutter. We present the following three principal contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Abstract**\n",
    "\n",
    "***\"We tackle the task of semantic alignment where the goal\n",
    "is to compute dense semantic correspondence aligning two\n",
    "images depicting objects of the same category.\"***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Contribution**\n",
    "\n",
    "---\n",
    "\n",
    "***First***, *we develop a convolutional neural network architecture for semantic alignment\n",
    "that is trainable in an end-to-end manner from weak image-level supervision in the form of matching image pairs.*\n",
    "\n",
    "> **Weak image-level supervision으로 End-to-End 학습 가능한 semantic alignment를 위한 CNN개발**\n",
    "\n",
    "---\n",
    "\n",
    "***Second***, *the main component of this architecture is a differentiable soft inlier scoring module, inspired by the RANSAC inlier scoring procedure, that computes the quality of the alignment based on only geometrically consistent correspondences thereby reducing the effect of background clutter.*\n",
    "\n",
    "> **RANSAC inlier scoring procedure에 영감을 받아서, background clutter 감소시키는 geometrically consistent correspondeces만 기반으로 하여 alignment quality computer하는  differentiable soft inlier scoring module 개발**\n",
    "\n",
    "---\n",
    "\n",
    "***Third***, *we demonstrate that the proposed approach achieves state-of-the-art\n",
    "performance on multiple standard benchmarks for semantic\n",
    "alignment.*\n",
    "\n",
    "> **여기서는 정성적 평가. 여러 Semantic alignment에 있어서 소타 달성**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "![](https://www.di.ens.fr/willow/research/weakalign/images/teaser.jpg)\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "        </td>\n",
    "        <td>\n",
    "            <span>\n",
    "                <i>\"Figure 1: We describe a CNN architecture that, given an input image pair (top), outputs dense semantic correspondence between the\n",
    "                two images together with the aligning geometric transformation\n",
    "                (middle) and discards geometrically inconsistent matches (bottom). The alignment model is learnt from weak supervision in\n",
    "                the form of matching image pairs without correspondences.\"\n",
    "                </i>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "*\"Finding correspondence is one of the fundamental problems in computer vision. Initial work has focused on finding correspondence between images depicting the same object or scene with applications in image stitching [30], multiview 3D reconstruction [11], motion estimation [6, 33] or tracking [4, 22].*\"\n",
    "\n",
    "> **Correspondence는 비젼에서 근본적인 문제 중 하나. Inital work는 image stitching이나 multiview 3D reconstruction, motion estimation이나 tracking에서 같은 object나 scene을 찾는 방법에 초점**\n",
    "\n",
    "***\"In this work we study the problem of finding category-level correspondence, or semantic alignment [1, 20], where the goal is to establish dense correspondence between different objects belonging to the same category, such as the two different motorcycles illustrated in Fig. 1. This is an important problem with applications in object recognition [19], image editing [3], or robotics [23].\"***\n",
    "\n",
    "> **이 논문에서는 위 figure처럼 같은 카테고리에서 다른 object 간에 dense correspondence하는게 목표.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Related Works**\n",
    "\n",
    "#### **Matching with hand-crafted image descriptors**\n",
    "\n",
    "- **What is it**: *\"Traditionally, correspondences between images\n",
    "have been obtained by hand crafted local invariant feature detectors and descriptors [23, 25, 42]\n",
    "that were extracted from the image with a controlled degree of invariance to local geometric and\n",
    "photometric transformations. Candidate (tentative) correspondences were then obtained by variants\n",
    "of nearest neighbour matching. Strategies for removing ambiguous and non-distinctive matches\n",
    "include the widely used second nearest neighbour ratio test [23], or enforcing matches to be mutual\n",
    "nearest neighbours.\"*\n",
    "\n",
    "- **Limitation**: \"*Both approaches work well for many applications, but have the disadvantage\n",
    "of discarding many correct matches, which can be problematic for challenging scenes, such as\n",
    "indoor spaces considered in this work that include repetitive and textureless areas. While successful,\n",
    "handcrafted descriptors have only limited tolerance to large appearance changes beyond the built-in\n",
    "invariance.*\"\n",
    "\n",
    "> **전통적으로, Correspondence는 local invariant feature (상대적으로 안변하는 local feautre들) 중심으로 Candidate correspondences (애매모한 애들)을 nearest neighbour참고하여 처리. 즉 nearest neighbour을 information삼는 방식은 예전에도 hand crafted된 방식으로 존재.**\n",
    "\n",
    "\n",
    "> **하지만 Indoor나 반복적이고 textureless한 scene들은 잘 처리하지 못함. 즉, INVARIANCE가 뚜렷하게 탑재된 큰 변화에 있어서 한계적으로 작동**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Matching with trainable descriptors.**\n",
    "\n",
    "- **What is it**: *\"The majority of trainable image descriptors are based on\n",
    "convolutional neural networks (CNNs) and typically operate on patches extracted using a feature\n",
    "detector such as DoG [23], yielding a sparse set of descriptors [3, 4, 10, 17, 36, 37] or use a pre-trained\n",
    "image-level CNN feature extractor [26, 32]. Others have recently developed trainable methods that\n",
    "comprise both feature detection and description [7, 26, 43]. The extracted descriptors are typically\n",
    "compared using the Euclidean distance,\"*\n",
    "\n",
    "- **Limitation**: *\"but an appropriate similarity score can be also learnt in\n",
    "a discriminative manner [13, 44], where a trainable model is used to both extract descriptors and produce a similarity score. Finding matches consistent with a geometric model is typically performed\n",
    "in a separate post-processing stage [3, 4, 7, 10, 17, 22, 26, 36, 37, 43].\"*\n",
    "\n",
    "> **trainable한 친구들은 CNN기반. patch 단위로 feature extracting 하거나 (DoG) / sprase set descriptors 적용하거나 / pre-trained된 image-level CNN feautre extractor 적용. feature detection과 description에 있어서 둘다 trainable한 methods 적용한 애들도 있음. 걔네들 descriptors는 유클라디언 distance를 주로 사용.**\n",
    "\n",
    "> **그러나 trainable model 같은 경우 extract descriptors하고 유사도 도출하는데 둘다쓰임. matching은 별도의 다른 stage로 구분되어 사용해야 했음**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Trainable image alignment.**\n",
    "\n",
    "- **What is it**: *\"Recently, end-to-end trainable methods have been developed to\n",
    "produce correspondences between images according to a parametric geometric model, such as an\n",
    "affine, perspective or thin-plate spline transformation [28, 29]. In these works, all pairwise feature\n",
    "matches are computed and used to estimate the geometric transformation parameters using a CNN.*\n",
    "***Unlike previous methods that capture only a sparse set of correspondences, this geometric estimation\n",
    "CNN captures interactions between a full set of dense correspondences.\"***\n",
    "\n",
    "- **Limitation**:  \"*However, these methods\n",
    "currently only estimate a low complexity parametric transformation, and therefore their application\n",
    "is limited to only coarse image alignment tasks.*\"\n",
    "\n",
    "- **Solution**: *\"In contrast, we target a more general problem of\n",
    "identifying reliable correspondences between images of a general 3D scene. Our approach is not\n",
    "limited to a low dimensional parametric model, but outputs a generic set of locally consistent image\n",
    "correspondences, applicable to a wide range of computer vision problems ranging from category-level\n",
    "image alignment to camera pose estimation. The proposed method builds on the classical ideas of\n",
    "neighbourhood consensus, which we review next.\"*\n",
    "\n",
    "> **최근에 나온 End to End trainable한 Correspondence한 Methods들은 parametic geometric model로 이전 모델들이 sparse한 correspondences를 검출하는 반면에 전체의 dense correspondences를 검출. 그러나 아직은 low complexity parametic transformation에 그쳐서 coarse한 이미지 alignment task에 머물고 있음.**\n",
    "\n",
    "> **반면에 해당 논문의 method는 low dimensional parametric model에 그치지 않고, 3D scene의 일반적인 이미지의 안정적인 correspondeces를 통해 넓은 비젼분야에 걸쳐서 적용가능한 (category-level에서 부터 camera pose estimation까지) method임. 이 기본 아이디어는 향후 설명할 Neighbourhood consensus임.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Match filtering by neighbourhood consensus**\n",
    "\n",
    "- **What is it**: *\"Several strategies have been introduced to decide\n",
    "whether a match is correct or not, given the supporting evidence from the neighbouring matches. The\n",
    "early examples analyzed the patterns of* ***distances [46] or angles [34] between neighbouring matches.***\n",
    "*Later work simply counts the number of consistent matches in a certain image neighbourhood [33, 38],\n",
    "which can be built in a scale invariant manner [30] or using a regular image grid [5]. While\n",
    "simple, these techniques have been remarkably effective in removing random incorrect matches and\n",
    "disambiguating local repetitive patterns [30].\"*\n",
    "\n",
    "- **Solution**: *\"Inspired by this simple yet powerful idea we develop a\n",
    "neighbourhood consensus network – a convolutional neural architecture that (i) analyzes the full set of\n",
    "dense matches between a pair of images and (ii) learns patterns of locally consistent correspondences\n",
    "directly from data.\"*\n",
    "\n",
    "> **Neigbouring을 heurestic으로 matching하는 여러 방법들이 존재하였음. 몇몇 방법들은 neigbouring 매치들간에 거리나 각도의 패턴을 분석함으로써 구현하였고, 나중에 몇몇 작업들은 확실한 neigbourhood 이미지에서 consistent matches들을 세는 방법으로 구현. 이는 잘못된 matches와 애매모한 반복적인 local 패턴들을 제거하는데 효과적.**\n",
    "\n",
    "> **여기에 영감을 받아서 CNN기반의 neighbourhood consensus network 개발. \n",
    " (i) pair 이미지 전체 set에 대한 dense matches (ii) 데이터로부터 directly하게 locally consistent correpondeces 패턴까지 학습**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Flow and disparity estimation**\n",
    "\n",
    "- **What is it**: *\"Related are also methods that estimate optical flow or stereo\n",
    "disparity such as [6, 15, 16, 24, 39], or their trainable counterparts [8, 19, 40]. These works also aim\n",
    "at establishing reliable point to point correspondences between images.\"*\n",
    "\n",
    "- **Limitation**: *\"This(our method) is different from optical flow where\n",
    "image pairs are usually consecutive video frames with small viewpoint or appearance changes, and\n",
    "stereo where matching is often reduced to a local search around epipolar lines. The optical flow\n",
    "and stereo problems are well addressed by specialized methods that explicitly exploit the problem\n",
    "constraints (such as epipolar line constraint, small motion, smoothness, etc.).\"*\n",
    "\n",
    "- **Solution**: *\"However, we address a more\n",
    "general matching problem where images can have large viewpoint changes (indoor localization) or\n",
    "major changes in appearance (category-level matching).*\n",
    "\n",
    "> **optical flow나 stereo disparity(치우침) 측정을 위한 방법들과 trainable한 counterparts들에 대한 methods들도 존재. 그러나 optical flow는 small viewpoint 나 appearance changes에 대해서 consecutive한 video frames들을 갖음. 또한 local search를 위해서 epipolar liines들 주변에서 매칭이 줄어드는 경향. 이러한 optical flow는 epipolar line constraint나 small motion, smoothness들을 가지고 처리하는데 특화되있음.**\n",
    "\n",
    "> **그러나 해당 논문에서는 좀 더 general한 matching을 위해서 더 large한 viewpoint changes (indoor localization) 과 major changes in appearance (category-level matching)을 해결하고자 함.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Proposed approach**\n",
    "\n",
    "***\"In this work, we combine the robustness of neighbourhood consensus filtering with the power of\n",
    "trainable neural architectures.\"***\n",
    "\n",
    ">\n",
    "\n",
    "- *We design a model which learns to discriminate a reliable match by\n",
    "recognizing patterns of supporting matches in its neighbourhood.*\n",
    "\n",
    ">\n",
    "\n",
    "- *Furthermore, we do this in a fully\n",
    "differentiable way, such that this trainable matching module can be directly combined with strong\n",
    "CNN image descriptors. The resulting pipeline can then be trained in an end-to-end manner for the\n",
    "task of feature matching. An overview of our proposed approach is presented in Fig. 1.*\n",
    "\n",
    ">\n",
    "\n",
    "- *There are five main components: (i) dense feature extraction and matching, (ii) the neighbourhood consensus\n",
    "network, (iii) a soft mutual nearest neighbour filtering, (iv) extraction of correspondences from the\n",
    "output 4D filtered match tensor, and (v) weakly supervised training loss. These components are\n",
    "described next.*\n",
    "\n",
    ">\n",
    "\n",
    "#### **Dense feature extraction and matching**\n",
    "\n",
    "![](https://www.di.ens.fr/willow/research/ncnet/images/teaser.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### **Neighbourhood consensus network**\n",
    "---\n",
    "\n",
    "#### **Soft mutual nearest neighbour filtering**\n",
    "---\n",
    "\n",
    "#### **Extracting correspondences from the correlation map**\n",
    "---\n",
    "\n",
    "#### **Weakly-supervised training**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experimental results**\n",
    "\n",
    "#### **Implementation details**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Category-level matching**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Instance-level matching**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Limitations**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('buddhalight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
