{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neighbourhood Consensus Networks**\n",
    "\n",
    "**Authors: Ignacio Rocco†, Mircea Cimpoi‡, Relja Arandjelovic´\n",
    "§, Akihiko Torii∗,\n",
    "Tomas Pajdla‡, Josef Sivic†,‡**\n",
    "\n",
    "**†Inria / ‡CIIRC, CTU in Prague / §DeepMind / ∗Tokyo Institute of Technology**\n",
    "\n",
    "**Unofficial Github Code**: https://github.com/ignacio-rocco/ncnet\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited March 21 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Abstract**\n",
    "\n",
    "***\"We address the problem of finding reliable dense correspondences between a pair\n",
    "of images\"***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contribution**\n",
    "\n",
    "---\n",
    "*1. Inspired by the classic idea of disambiguating feature matches using semi-local constraints, we develop an end-to-end trainable convolutional neural network architecture that identifies sets of spatially consistent matches by analyzing neighbourhood consensus patterns in the 4D space of all possible correspondences between a pair of images without the need for a global geometric model.*\n",
    "\n",
    "> ***Semi-Local Constraints*를 이용하여 애매모한 Feature를 매칭시키는 클래식한 아이디어에서 영감을 얻은바,**\n",
    "\n",
    "- **Global Gemoetric Model**의 필요 없이, \n",
    "\n",
    "- **4D Space**에서 가능한 모든 neighbourhood consensus 패턴들을 분석해서 spatially matching하는, \n",
    "\n",
    "- **End-to-End**로 **Trainable**, 즉 학습가능한 CNN Architecture를 개발.\n",
    "---\n",
    "\n",
    "*2. We demonstrate that the model can be trained effectively from weak supervision in the form of matching and non-matching image pairs without the need for costly manual annotation of point to point correspondences.*\n",
    "\n",
    "> **Manual annotation, 즉 완전 하드 annotated 방식이 아닌 **matching**과 **non-matchinig** **image pairs** 형태를 갖춘 **weak supervision**을 통해 **효율적 학습****\n",
    "\n",
    "---\n",
    "\n",
    "*3. We show the proposed neighbourhood consensusnetwork can be applied to a range of matching tasks including both category- and instance-level matching, obtaining the state-of-the-art results on the PF Pascal dataset and the InLoc indoor visual localization benchmark.*\n",
    "\n",
    "> **여기서는 정성적 평가. Neighbourhood Consensus Network는 **Category**, **Instance-level Matching**을 포함한 넓은 matching task에서**\n",
    "\n",
    "- **PF PASCAL 데이터셋과**\n",
    "- **InLoc Indoor Visual Localization** 벤치마크에서\n",
    "- 소타달성.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('buddhalight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
