{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Neighbourhood Consensus Networks**\n",
    "\n",
    "**Authors: Ignacio Rocco†, Mircea Cimpoi‡, Relja Arandjelovic´\n",
    "§, Akihiko Torii∗,\n",
    "Tomas Pajdla‡, Josef Sivic†,‡**\n",
    "\n",
    "**†Inria / ‡CIIRC, CTU in Prague / §DeepMind / ∗Tokyo Institute of Technology**\n",
    "\n",
    "**Unofficial Github Code**: https://github.com/ignacio-rocco/ncnet\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited March 21 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***\"좁게보면 안보이는 독특한 Feature들을 넓은 Context에서 찾으므로써, 애매모한 것들을 다 처리하자! + CNN 기반 완전 differentiable(=End to End학습 가능한) 아키텍쳐 구축\"***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Abstract**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Contribution**\n",
    "\n",
    "---\n",
    "\n",
    "***First**, Inspired by the classic idea of disambiguating feature matches using semi-local constraints, we develop an end-to-end trainable convolutional neural network architecture that identifies sets of spatially consistent matches by analyzing neighbourhood consensus patterns in the 4D space of all possible correspondences between a pair of images without the need for a global geometric model.*\n",
    "\n",
    "> ***Semi-Local Constraints*를 이용하여 애매모한 Feature를 매칭시키는 클래식한 아이디어에서 영감을 얻은바, Global Gemoetric Model의 필요 없이, 4D Space에서 가능한 모든 neighbourhood consensus 패턴들을 분석해서 spatially matching하는, End-to-End로 학습가능한 CNN Architecture를 개발.**\n",
    "\n",
    "---\n",
    "\n",
    "***Second**, We demonstrate that the model can be trained effectively from weak supervision in the form of matching and non-matching image pairs without the need for costly manual annotation of point to point correspondences.*\n",
    "\n",
    "> **Manual annotation, 즉 완전 하드 annotated 방식이 아닌 matching과 non-matchinig image pairs 형태를 갖춘 weak supervision을 통해 효율적 학습**\n",
    "\n",
    "---\n",
    "\n",
    "***Third**, We show the proposed neighbourhood consensusnetwork can be applied to a range of matching tasks including both category- and instance-level matching, obtaining the state-of-the-art results on the PF Pascal dataset and the InLoc indoor visual localization benchmark.*\n",
    "\n",
    "> **여기서는 정성적 평가. Neighbourhood Consensus Network는 Category, Instance-level Matching을 포함한 넓은 matching task에서 PF PASCAL 데이터셋과 InLoc Indoor Visual Localization 벤치마크에서 소타달성.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "> **기존의 Visual Correspondence는 *Viewpoint*의 변화나, *illumination* 등 다양한 variation에 꽤 괜찮은 결과를 낳았으나, 여전히 hand-crafted - 여기서 hand crafted는 hardly annotated된 걸로 이해하였음.- 된 Model이 최고의 성능을 보이고 있음. (OD나 Classification과 다르게)**\n",
    "\n",
    "*\"One of the reasons for this plateauing performance could be the currently dominant approach for\n",
    "finding image correspondence based on matching individual image features. While we have now better\n",
    "local patch descriptors, the matching is still performed by variants of the nearest neighbour assignment\n",
    "in a feature space followed by separate disambiguation stages based on geometric constraints.\"*\n",
    "\n",
    "> **애매모하고 variate한 feature들 분리하고, invariate한 부분들 위주로 가장 가까운 neighbour을 갖다가 assign해버리는 individual image feature 기반의 image correspondence 가 dominant한 approach.**\n",
    "\n",
    "*\"This\n",
    "approach has, however, fundamental limitations. Imagine a scene with textureless regions or repetitive\n",
    "patterns, such as a corridor with almost textureless walls and only few distinguishing features. A\n",
    "small patch of an image, depicting a repetitive pattern or a textureless area, is indistinguishable from other portions of the image depicting the same repetitive or textureless pattern. Such matches will be\n",
    "either discarded [23] or incorrect. As a result, matching individual patch descriptors will often fail in\n",
    "such challenging situations.\"*\n",
    "\n",
    "> **그러나 이건 근본적인 문제점. Textureless한 region 또는 반복되는 패턴의 회랑 같은 것들은 조금의 분류가능한 feature들을 가지고 있음. 때문에 이러한 Individual한 patch descriptors는 이러한 challenging한 상황에서 실패**\n",
    "\n",
    "\n",
    "*\"In this work we take a different direction and develop a trainable neural network architecture that\n",
    "disambiguates such challenging situations by analyzing local neighbourhood patterns in a full set of\n",
    "dense correspondences. **The intuition is the following: in order to disambiguate a match on a repetitive\n",
    "pattern, it is necessary to analyze a larger context of the scene that contains a unique non-repetitive\n",
    "feature.** The information from this unique match can then be propagated to the neighbouring uncertain\n",
    "matches. In other words, the certain unique matches will support the close-by uncertain ambiguous\n",
    "matches in the image.\"*\n",
    "\n",
    "> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3efb3a3e09a38f93b1d9bfa4b9b8ce66a167f6ada77b64bc003d7d6d298d81d5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('buddhalight')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
