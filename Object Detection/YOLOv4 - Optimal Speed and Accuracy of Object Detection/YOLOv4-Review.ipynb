{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YOLOv4: Optimal Speed and Accuracy of Object Detection**\n",
    "\n",
    "**Authors: Alexey Bochkovskiy {alexeyab84@gmail.com}, Chien-Yao Wang {kinyiu@iis.sinica.edu.tw}, Hong-Yuan Mark Liao {liao@iis.sinica.edu.tw}**\n",
    "\n",
    "**Official Github**: https://github.com/AlexeyAB/darknet\n",
    "\n",
    "---\n",
    "\n",
    "**Edited By Su Hyung Choi (Key Summary & Code Practice)**\n",
    "\n",
    "If you have any issues on this scripts, please PR to the repository below.\n",
    "\n",
    "**[Github: @JonyChoi - Computer Vision Paper Reviews]** https://github.com/jonychoi/Computer-Vision-Paper-Reviews\n",
    "\n",
    "Edited Jan 7 2022\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Abstract**\n",
    "\n",
    "So far, there are a huge number of **features** to improve the **CNN Accuracy**.\n",
    "\n",
    "- Some features are applicable on certain **exclusive environment(e.g models, problems etc.)**\n",
    "\n",
    "- And some features are applicable to the majority of models, tasks, and datasets. **(e.g small-scale datsets, batch-normalization, residual-connections etc.)**.\n",
    "\n",
    "The authors assumed that there are **universal features**, and created the new features belows\n",
    "\n",
    "- **WRC**: Weighted-Residual-Connections\n",
    "- **CSP**: Cross-Stage-Partial-connections\n",
    "- **CmBN**: Cross mini-Batch Normalization\n",
    "- **SAT**: Self-adversarial-training\n",
    "- **Mish-activation**\n",
    "\n",
    "+ Also they used other new feautures below (not assumed the universal features in context of abstract)\n",
    "\n",
    "- Mosaic data augmentation\n",
    "- DropBlock regularization\n",
    "- CIOU loss\n",
    "\n",
    "With using new **features**, and combining some of them, they achieved\n",
    "\n",
    "- **state-of-the-art results: 43.5% AP (65.7% AP50)** \n",
    "- for the MS COCO dataset\n",
    "- at a **realtime speed of ∼65 FPS**\n",
    "- on Tesla V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "#### **1. Trade offs between Accuracy & Speed**\n",
    "The majority of CNN-based object detectors are largely applicable **only** for recommendation systems.\n",
    "- **Example of Slow Accurate Models**: Searching Free parking place\n",
    "\n",
    "- **Example of Fast Inaccurate Models**: Car collision warning\n",
    "\n",
    "#### **2. Problems Authors Object**\n",
    "\n",
    "- The most accurate modern neural networks **do not operate in real time**.\n",
    "- The most accurate modern neural networks **require large number of GPUs** for training with a large mini-batch-size.\n",
    "\n",
    "#### **3. Solutions Authors Object**\n",
    "- Creating a CNN that operates **in real-time on a conventional GPU**.\n",
    "- Creating a CNN that **training requires only one conventional GPU** like 1080Ti for everyone can train.\n",
    "\n",
    "#### **4. Main Goal**\n",
    "\n",
    "- **Designing a fast operating speed of an object detector in production systems and optimization for parallel computations that can be easily trained and used.**\n",
    "\n",
    "#### **5. Contributions**\n",
    "\n",
    "1. **Develop an efficient and powerful object detection model that everyone can use a 1080 Ti or 2080 Ti GPU to train.**\n",
    "\n",
    "2. Verify the influence of state-of-the-art Bag-ofFreebies and Bag-of-Specials methods of object detection during the detector training.\n",
    "\n",
    "3. Modify state-of-the-art methods and make them more effecient and suitable for single GPU training, including CBN [89], PAN [49], SAM [85], etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Related Work**\n",
    "\n",
    "#### **1. Modern Detector**\n",
    "Usually composed of two parts.\n",
    "- ***Backbone*** pre-trained on ImageNet.\n",
    "- ***Head*** used to **predict classes** and **bounding boxes** of objects.\n",
    "\n",
    "#### **2. Backbones**\n",
    "\n",
    "Backbones can be classified according to platform(GPU, CPU)\n",
    "\n",
    "**Backbones on GPU Platform**\n",
    "\n",
    "- VGG [68]\n",
    "- ResNet [26]\n",
    "- ResNeXt [86]\n",
    "- DenseNet [30]\n",
    "\n",
    "**Backbones on CPU Platform**\n",
    "\n",
    "- SqueezeNet [31]\n",
    "- MobileNet [28, 66, 27, 74]\n",
    "- ShuffleNet [97, 53]\n",
    "\n",
    "#### **3. Head**\n",
    "\n",
    "As to the head part, it is usually categorized into two kinds(**one-stage** object detector, **two-stage** object detector)\n",
    "\n",
    "The representative object detectors are below.\n",
    "\n",
    "\n",
    "**Two-Stage-Detector**\n",
    "\n",
    "- R-CNN [19] series: fast R-CNN [18], faster R-CNN [64], R-FCN [9]\n",
    "- Libra R-CNN [58]\n",
    "\n",
    "**Two-Stage-Detector with anchor-free**\n",
    "- RepPoints [87]\n",
    "\n",
    "\n",
    "**One-Stage-Detector**\n",
    "\n",
    "- YOLO\n",
    "- SSD\n",
    "- RetinaNet\n",
    "\n",
    "**One-Stage-Detector with anchor-free**\n",
    "- CenterNet [13]\n",
    "- CornerNet [37, 38]\n",
    "- FCOS [78]\n",
    "\n",
    "#### **4. Neck**\n",
    "\n",
    "Recently Object Detectors inserting some layers between backbone and head are developed. \n",
    "\n",
    "These layers are usually used to collect feature maps from different stages\n",
    "\n",
    "Usually, a neck is composed of several **bottom-up paths** and several **topdown paths**. \n",
    "\n",
    "Networks equipped with this mechanism are below.\n",
    "\n",
    "- Feature Pyramid Network (FPN) [44]\n",
    "- Path Aggregation Network (PAN) [49]\n",
    "- BiFPN [77]\n",
    "- NAS-FPN [17]\n",
    "\n",
    "#### **5. New Backbone**\n",
    "\n",
    "In addition to the above models, some researchers put their emphasis on directly building a new backbone\n",
    "- DetNet [43]\n",
    "- DetNAS [7] \n",
    "\n",
    "#### **6. Whole New Model**\n",
    "- SpineNet [12]\n",
    "- HitDetector [20]\n",
    "---\n",
    "### **Terminologies**\n",
    "\n",
    "**1. Dense Prediction**\n",
    "\n",
    "***== \"Semantic image segmentation\"***\n",
    "\n",
    "Classify all pixels in the picture into corresponding class(a predetermined number). It is also called dense prediction because it predicts all pixels in the image.\n",
    "\n",
    "<img src=\"https://images.deepai.org/converted-papers/1809.04184/x1.png\" width=\"500\">\n",
    "\n",
    "**2. Sparse Prediction**\n",
    "\n",
    "Sparse Prediction seems to be dubbed since its network propose the ***\"sparse\"*** proposal region from the ***a huge number of predicted boxes*** (Fast R-CNN etc.) or ***predict only sparse boxes at the inital*** (Sparse R-CNN).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2000/0*vhzrGqMMGQIyxg66.jpeg\" height=\"300\">\n",
    "\n",
    "[Figure: The road to Sparse R-CNN — key ideas and intuition](https://medium.com/responsibleml/the-road-to-sparse-r-cnn-key-ideas-and-intuition-feb184d0d4f3)\n",
    "\n",
    "**3. Anchor Free**\n",
    "\n",
    "<---> ***\"Anchor based detector\"***\n",
    "\n",
    "The object detection problem was mainly studied on anchor-based detectors. The anchor-based detector is a method of predicting categories and adjusting coordinates in numerous preset anchors. There are two-stage methods and one-stage methods.\n",
    "\n",
    "However, due to the recent emergence of FPN and Local Loss, research on the anchor-free detector method is being conducted. The anchor-free detector can immediately find the object without an anchor. There are two methods: a keypoint-based method of predicting the location of an object using keypoints and a center-based method of predicting the distance of the object boundary if positive after predicting the center of the object. This anchor-free detector is considered to have more potential in the field of object detection because it obtains similar performance to anchor-based detector without using a hyperparameter related to anchor.\n",
    "\n",
    "The center-based detector is similar to the anchor-based detector in that it uses points instead of the anchor box.\n",
    "\n",
    "https://byeongjokim.github.io/posts/Bridging-the-Gap-Between-Anchor-based-and-Anchor-free-Detection-via-Adaptive-Training-Sample-Selection/\n",
    "\n",
    "**4. Neck**\n",
    "\n",
    "As the name suggests, it is a connection between the backbone and head. Neck extracts different feature maps from different stages of the backbone, such as FPN, PANet, Bi-FPN, etc.\n",
    "\n",
    "For example here, the below is ***FPN***, the Feature Pyramid Network. [About FPN(Feature Pyramid Network)](https://github.com/jonychoi/Computer-Vision-Paper-Reviews/tree/main/Feature%20Pyramid%20Networks%20for%20Object%20Detection)\n",
    "\n",
    "<img src=\"https://media.vlpt.us/images/hewas1230/post/94c179ec-f5cb-4729-bbf0-89fcc2d9722a/image.png\" />\n",
    "\n",
    "The FPN **enhance the existing convolutional network** through the top-down method and side connection. This allows the network to configure rich feature pyramids and diverse scales from single resolution input images. \n",
    "\n",
    "<img src=\"https://media.vlpt.us/images/hewas1230/post/b6a6c808-9e73-4c08-b51a-3d08439df63f/image.png\" />\n",
    "\n",
    "Each side connection creates a different pyramid level by merging feature maps from bottom-up pathway to top-down pathway. Before merging Feature maps, the previous pyramid level is up-sampled by the 2x element of the FPN to have the same spatial size.\n",
    "\n",
    "Thanks to these various layers, classification or regression network (Head) can be applied to each layer to detect objects of different sizes.\n",
    "\n",
    "<img src=\"https://media.vlpt.us/images/hewas1230/post/9bf68005-46d5-4ccd-be37-91df562852f8/image.png\" />\n",
    "\n",
    "(a) shows how features are extracted from the backbone of a single shot detector architecture (SSD). \n",
    "\n",
    "(b) is the FPN method (FPN uses ResNet)\n",
    "\n",
    "(c) the STDN method, and (d) the YOLOv4 method.\n",
    "\n",
    "\n",
    "In conclusion, the idea of \"giving various scale changes to detect objects through pyramid forms\" is all the same.\n",
    "\n",
    "[Reference: Object-Detection Architecture](https://velog.io/@hewas1230/ObjectDetection-Architecture)\n",
    "\n",
    "**4.1 Neck - Additional blocks**\n",
    "\n",
    "**4.2 Neck - Path-aggregation blocks**\n",
    "\n",
    "\n",
    "**5. Heads**\n",
    "\n",
    "It is a practical part of 'detection' such as tasking classification and regression of the bounding boxes. Output is in the form of four values (x, y, h, w) and the probability of k classes + 1 (+1 is for background).\n",
    "\n",
    "Since the Object Detector vary to two models depends on End to End feature extraction and classification or feature extraction and classification with restricted number of boxes(sparse), upon, we can classify the object detectors as **Dense Prediction (one-stage)** and **Sparse Prediction (two-stage)**.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8574845d26991fb924b9b73a047d47daa16a02e6e1ac35bb3c12f8621974ea3"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('buddhalight3.6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
